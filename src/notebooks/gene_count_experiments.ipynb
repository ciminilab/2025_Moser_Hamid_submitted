{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene count VAE experiments\n",
    "Experiments with spatial data: The VAE is trained with the gene count vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.vae_model.linear_vae import VAE_LINEAR\n",
    "from models.vae_model.model_config import LinearVAEConfig\n",
    "from models.loss_functions import mse_loss_function\n",
    "from dataset.gene_counts_dataset import GeneCountDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"_data_/segmentation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "CUDA_DEVICE_NUM = 2\n",
    "DEVICE = torch.device(f'cuda:{CUDA_DEVICE_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helperfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_gene_count_reconstruction(vae_model, test_data_iterator):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(10, 2))\n",
    "\n",
    "    test_batch = next(test_data_iterator)\n",
    "    example_images = test_batch[0].to(DEVICE)\n",
    "    x_flat, _, _ = vae_model(example_images)\n",
    "    x_reconstructed = x_flat.view(-1, 1, 5, 23)\n",
    "\n",
    "    for i in range(4):\n",
    "        img = example_images[i].cpu().detach().numpy()\n",
    "        img_reshaped = np.squeeze(img).reshape((5, 23))\n",
    "        img_recon = x_reconstructed[i].cpu().detach().numpy()\n",
    "\n",
    "        uint8_image = img_reshaped.astype(np.uint8)\n",
    "        uint8_image_recon = np.squeeze(img_recon).astype(np.uint8)\n",
    "\n",
    "        axes[0, i].imshow(uint8_image, cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        axes[1, i].imshow(uint8_image_recon, cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    fig.suptitle('Reconstruction examples', fontsize=16, y=0.8)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene count experiment\n",
    "This experiment uses the gene counts as input samples.  \n",
    "Each input `x` is a vectore of length 115 which represents the count per gene of in the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "N_GENES = 115\n",
    "Z_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_config = {\n",
    "    \"model_config\": {\n",
    "        \"hidden_dims\": [300, 200, 100], # Dimmension of hidden layers\n",
    "        \"z_dim\": Z_DIM,\n",
    "        \"input_dim\": N_GENES\n",
    "    },\n",
    "    \"hyperparameters\": {\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE\n",
    "    }\n",
    "}\n",
    "config_object = LinearVAEConfig(**linear_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_meta_df = pd.read_csv(os.path.join(DATA_PATH, \"cell_meta_data.csv\"))\n",
    "\n",
    "gene_count_df = pd.read_csv(os.path.join(DATA_PATH, \"gene_counts.csv\"))\n",
    "gene_count_df.set_index(\"cell_index\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>barcode_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>cell_index</th>\n",
       "      <th>fov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tmem119</td>\n",
       "      <td>104</td>\n",
       "      <td>1488.30760</td>\n",
       "      <td>275.79810</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tmem119</td>\n",
       "      <td>104</td>\n",
       "      <td>1917.46340</td>\n",
       "      <td>1550.89270</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tmem119</td>\n",
       "      <td>104</td>\n",
       "      <td>1507.42460</td>\n",
       "      <td>1828.72770</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fcrls</td>\n",
       "      <td>40</td>\n",
       "      <td>1311.61820</td>\n",
       "      <td>1308.89880</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eif3f</td>\n",
       "      <td>34</td>\n",
       "      <td>1511.89420</td>\n",
       "      <td>81.69420</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11867300</th>\n",
       "      <td>Shroom3</td>\n",
       "      <td>35</td>\n",
       "      <td>376.57013</td>\n",
       "      <td>481.29892</td>\n",
       "      <td>119_0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11867301</th>\n",
       "      <td>Bcl11b</td>\n",
       "      <td>3</td>\n",
       "      <td>354.98557</td>\n",
       "      <td>471.98940</td>\n",
       "      <td>119_0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11867302</th>\n",
       "      <td>Moxd1</td>\n",
       "      <td>26</td>\n",
       "      <td>722.20416</td>\n",
       "      <td>1789.81980</td>\n",
       "      <td>119_0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11867303</th>\n",
       "      <td>Neurod2</td>\n",
       "      <td>28</td>\n",
       "      <td>353.81418</td>\n",
       "      <td>467.59146</td>\n",
       "      <td>119_0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11867304</th>\n",
       "      <td>Aldh1l1</td>\n",
       "      <td>1</td>\n",
       "      <td>507.14630</td>\n",
       "      <td>871.74225</td>\n",
       "      <td>119_0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11867305 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             gene  barcode_id           x           y cell_index  fov\n",
       "0         Tmem119         104  1488.30760   275.79810        0_0    0\n",
       "1         Tmem119         104  1917.46340  1550.89270        0_0    0\n",
       "2         Tmem119         104  1507.42460  1828.72770        0_0    0\n",
       "3           Fcrls          40  1311.61820  1308.89880        0_0    0\n",
       "4           Eif3f          34  1511.89420    81.69420        0_0    0\n",
       "...           ...         ...         ...         ...        ...  ...\n",
       "11867300  Shroom3          35   376.57013   481.29892      119_0  119\n",
       "11867301   Bcl11b           3   354.98557   471.98940      119_0  119\n",
       "11867302    Moxd1          26   722.20416  1789.81980      119_0  119\n",
       "11867303  Neurod2          28   353.81418   467.59146      119_0  119\n",
       "11867304  Aldh1l1           1   507.14630   871.74225      119_0  119\n",
       "\n",
       "[11867305 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_meta_df = pd.read_csv(os.path.join(DATA_PATH, \"transcripts.csv\"))\n",
    "cell_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fov_range = range(52)\n",
    "gene_count_train_dataset = GeneCountDataset(\n",
    "    cell_meta_df=cell_meta_df[cell_meta_df['fov'].isin(training_fov_range)],\n",
    "    gene_count_df=gene_count_df\n",
    ")\n",
    "gene_count_train_loader = DataLoader(dataset=gene_count_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_fov_range = range(52, 60)\n",
    "gene_count_test_dataset = GeneCountDataset(\n",
    "    cell_meta_df=cell_meta_df[cell_meta_df['fov'].isin(test_fov_range)],\n",
    "    gene_count_df=gene_count_df\n",
    ")\n",
    "gene_count_test_loader = DataLoader(dataset=gene_count_test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_data_iterator = iter(gene_count_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_linear = VAE_LINEAR(config_object.model_config)\n",
    "vae_linear.to(DEVICE)\n",
    "\n",
    "# calculate the 'kl_weight'\n",
    "kl_weight = BATCH_SIZE / len(gene_count_train_loader.dataset)\n",
    "\n",
    "loss_function = mse_loss_function(kl_weight, 1)\n",
    "optimizer = torch.optim.Adam(vae_linear.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input x: torch.Size([32, 115])\n",
      "Shape of encoded x: torch.Size([32, 100])\n",
      "Shape of latent vector z: torch.Size([32, 50])\n",
      "Shape of reconstructed x: torch.Size([32, 115])\n"
     ]
    }
   ],
   "source": [
    "test_batch = next(test_data_iterator)\n",
    "example_images = test_batch[0].to(DEVICE)\n",
    "vae_linear.test_shape(example_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 8.5595\n",
      "Epoch: 10, Loss: 8.5341\n",
      "Epoch: 15, Loss: 10.2943\n",
      "Epoch: 20, Loss: 10.4700\n",
      "Epoch: 25, Loss: 22.2849\n",
      "Epoch: 30, Loss: 12.9042\n",
      "Epoch: 35, Loss: 7.1193\n",
      "Epoch: 40, Loss: 7.5236\n",
      "Epoch: 45, Loss: 11.9259\n",
      "Epoch: 50, Loss: 4.1871\n",
      "Best loss: 2.7663 in epoch: 42\n"
     ]
    }
   ],
   "source": [
    "float32_info = torch.finfo(torch.float32)\n",
    "min_training_loss = (-1, float32_info.max)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (features, _) in enumerate(gene_count_train_loader):\n",
    "        x = features.to(DEVICE)\n",
    "\n",
    "        x_recontsructed, z_mean, z_sigma = vae_linear.forward(x)\n",
    "        \n",
    "        loss = loss_function(x, x_recontsructed, z_mean, z_sigma)\n",
    "\n",
    "        loss_value = loss.item()\n",
    "        if loss_value < min_training_loss[1]:\n",
    "            min_training_loss = (epoch, loss_value)\n",
    "            torch.save(vae_linear.state_dict(), \"_data_/models/vae_linear_best_epoch.pt\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f'Epoch: {epoch+1}, Loss: {loss_value:.4f}')\n",
    "\n",
    "print(f'Best loss: {min_training_loss[1]:.4f} in epoch: {min_training_loss[0]+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model reconstruction\n",
    "Evaluate the best model on the test set by plotting reconstruction examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae_linear.load_state_dict(torch.load(\"_data_/models/vae_linear_best_epoch.pt\"))\n",
    "vae_linear.to(DEVICE)\n",
    "vae_linear.eval()\n",
    "\n",
    "visualize_gene_count_reconstruction(vae_linear, test_data_iterator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
